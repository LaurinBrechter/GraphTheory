{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The dataset consists of mails sent between Enron employees. \n",
    "- Each folder in the maildir directory represents a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:\\\\pythondata\\\\email\\\\enron_mail_20150507.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the contents of the tarred file and save the to our pwd\n",
    "tarfile.open(path, \"r\").extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Users: \", len(os.listdir(\"maildir\")))\n",
    "user_list = os.listdir(\"maildir\")\n",
    "c = 0\n",
    "\n",
    "for user in user_list:\n",
    "    if \"sent\" or \"sent_items\" in os.listdir(\"maildir\" + \"\\\\\" + user):\n",
    "        c += 1\n",
    "        \n",
    "print(c)\n",
    "    # sent_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "\n",
    "# loop through all of the users\n",
    "for j, user in enumerate(user_list[:10]):\n",
    "    \n",
    "    user_dir = os.path.join(\"maildir\", user)\n",
    "    \n",
    "    # if the user has a \"sent_items\" order use sent_items, otherwiese use the \"sent\" directory\n",
    "    if \"sent_items\" in os.listdir(user_dir):\n",
    "        path = os.path.join(\"maildir\", user, \"sent_items\")\n",
    "    elif \"sent\" in os.listdir(user_dir):\n",
    "        path = os.path.join(\"maildir\", user, \"sent\")\n",
    "        \n",
    "    # file names of all the mails the user sent.\n",
    "    mails = os.listdir(path)\n",
    "    \n",
    "    for i, mail in enumerate(mails):\n",
    "        with open(os.path.join(path, mail)) as f:\n",
    "            mail_content = \" \".join(f.read().split())\n",
    "            to = re.findall(r\"To: (.+?) Subject:\", mail_content)\n",
    "            \n",
    "            # add the users email to the node set.\n",
    "            if i == 0:\n",
    "                user_email = re.findall(r\"From: ([a-z0-9._%+-]+@[a-z0-9.-]+\\.[a-z]{2,}\\b)\", mail_content)[0]\n",
    "                g.add_node(user_email, company=\"enron\")\n",
    "                print(f\"Looking at connections of node: {user_email} Node {j} out of {c}\")\n",
    "            \n",
    "            if to != []:\n",
    "                for i in to[0].split(\",\"):  \n",
    "                    # confirm that the supposed target node really is an email address.\n",
    "                    if re.findall(r\"[a-z0-9._%+-]+@[a-z0-9.-]+\\.[a-z]{2,}\\b\", i) != []:\n",
    "                        \n",
    "                        # if the email address has the @enron.com we can confirm that the employees is at enron.\n",
    "                        if re.findall(r\"@enron\\.com\", i):\n",
    "                            g.add_node(i, company=\"enron\")\n",
    "                            g.add_edge(user_email, i)\n",
    "                        else:\n",
    "                            g.add_node(i, company=\"not_enron\")\n",
    "                            g.add_edge(user_email, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nx.get_node_attributes(g, \"company\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LIKE_EMAIL\": True}]\n",
    "\n",
    "matcher.add(\"EMAIL_ADRESS\", [pattern])\n",
    "\n",
    "doc = nlp(mail_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2197859665807148658, 23, 24), (2197859665807148658, 27, 28)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives back a tuple for each match. The first element of a lexeme, the next the start token and the last element the end token.\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL_ADRESS\n",
      "EMAIL_ADRESS\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    print(nlp.vocab[match[0]].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in doc.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at Doc2Vec and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar People"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict position in company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93ff2fb3ab55f45baf9b992255903249eaebee6bb8e37ed653eb50e096a7d927"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
